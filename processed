import os
import json
import warnings
from collections import defaultdict

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from joblib import dump


IN_CSV  = "features_data.csv"   
OUT_DIR = "processed"          


SEQ_LEN = 15
STRIDE  = 1
R_TRAIN, R_VAL, R_TEST = 0.70, 0.15, 0.15    
MIN_ROWS_PER_STOCK = 60                       


ADD_LABEL_LAGS   = True
LABEL_LAG_STEPS  = [1, 3, 5]                  


DATE_CANDS   = ["Date", "date", "交易日期", "时间", "Datetime", "datetime", "日期"]
STOCK_CANDS  = ["stock", "ticker", "ts_code", "code", "symbol", "证券代码", "股票代码", "S_INFO_WINDCODE"]
TARGET_CANDS = ["future_10d_return", "1_day_Return_next", "1d_return_next", "y_next", "target_next_return"]


EXCLUDE_COLS = {
    "label_binary"
}


def detect_col(cols, candidates):
    lowers = {c.lower(): c for c in cols}
    for k in candidates:
        if k.lower() in lowers:
            return lowers[k.lower()]
    for c in cols:
        lc = c.lower()
        for k in candidates:
            if k.lower() in lc:
                return c
    return None


def time_splits(n, r_train=0.7, r_val=0.15, r_test=0.15):
    assert abs(r_train + r_val + r_test - 1.0) < 1e-8
    n_train = int(n * r_train)
    n_val   = int(n * r_val)
    # n_test = n - n_train - n_val
    return (0, n_train), (n_train, n_train + n_val), (n_train + n_val, n)


def sliding_window(X2d: np.ndarray, y1d: np.ndarray, T: int, stride: int):
 
    N, C = X2d.shape
    xs, ys = [], []
    for start in range(0, N - T + 1, stride):
        end = start + T
        x = X2d[start:end]
        y = y1d[end - 1]
        if np.isnan(x).any() or np.isnan(y):
            continue
        xs.append(x)
        ys.append(y)
    if len(xs) == 0:
        return np.empty((0, T, C), dtype=float), np.empty((0,), dtype=int)
    return np.stack(xs, 0), np.array(ys, dtype=int)


def standardize_train_only(Xtr, Xva, Xte):
  
    if Xtr.size == 0:
        raise RuntimeError("standardize_train_only: empty Xtr")
    Ntr, T, C = Xtr.shape
    scaler = StandardScaler()
    Xtr2 = Xtr.reshape(Ntr * T, C)
    scaler.fit(Xtr2)

    def trf(X):
        N, T, C = X.shape
        X2 = X.reshape(N * T, C)
        X2 = scaler.transform(X2)
        return X2.reshape(N, T, C)

    return trf(Xtr), trf(Xva), trf(Xte), scaler


def main():
    if not os.path.exists(IN_CSV):
        raise FileNotFoundError(f"找不到输入文件：{IN_CSV}")

    os.makedirs(OUT_DIR, exist_ok=True)


    df = pd.read_csv(IN_CSV)
    all_cols = list(df.columns)


    date_col  = detect_col(all_cols, DATE_CANDS)
    stock_col = detect_col(all_cols, STOCK_CANDS)
    target_col_cand = detect_col(all_cols, TARGET_CANDS)

    if stock_col is None:
        raise RuntimeError(f"未探测到股票代码列，请包含列之一：{STOCK_CANDS}")

   
    if date_col is not None:
        df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
    else:
        warnings.warn("未检测到日期列，将按原始顺序处理。")

    
    if target_col_cand is None:
        if "label_binary" in df.columns:
            label_col = "label_binary"
        else:
            raise RuntimeError(f"未找到未来收益列（候选: {TARGET_CANDS}）或 label_binary 列，无法构造标签。")
    else:
        label_col = "label_binary"
        df[label_col] = (df[target_col_cand] > 0).astype(int)

    if ADD_LABEL_LAGS:
        if date_col is not None:
            df = df.sort_values(by=[stock_col, date_col]).reset_index(drop=True)
        else:
            df = df.sort_values(by=[stock_col]).reset_index(drop=True)

        for k in LABEL_LAG_STEPS:
            lag_name = f"{label_col}_lag{k}"
            df[lag_name] = (
                df.groupby(stock_col, sort=False)[label_col]
                  .shift(k)
                  .astype("float32")
            )

    df = df.replace([np.inf, -np.inf], np.nan)

    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    feature_cols = [c for c in numeric_cols if c not in EXCLUDE_COLS]
    for c in [label_col, stock_col, date_col]:
        if c in feature_cols:
            feature_cols.remove(c)

    if len(feature_cols) == 0:
        raise RuntimeError("无可用数值特征列，请检查。")

    stocks_sorted = sorted(df[stock_col].dropna().unique(), key=lambda x: str(x))

    Xtr_list, Xva_list, Xte_list = [], [], []
    ytr_list, yva_list, yte_list = [], [], []
    rows_meta = []
    cls_rows = []

    aligned_dfs = []

    for sid in stocks_sorted:
        sdf = df[df[stock_col] == sid].copy()
        if date_col is not None:
            sdf = sdf.sort_values(by=date_col).reset_index(drop=True)

        need_cols = feature_cols + [label_col]
        sdf = sdf[~sdf[need_cols].isna().any(axis=1)].reset_index(drop=True)

        if len(sdf) < MIN_ROWS_PER_STOCK:
            continue

        aligned_cols = []
        if stock_col is not None:
            aligned_cols.append(stock_col)
        if date_col is not None and date_col not in aligned_cols:
            aligned_cols.append(date_col)
        for c in feature_cols:
            if c not in aligned_cols:
                aligned_cols.append(c)
        if label_col not in aligned_cols:
            aligned_cols.append(label_col)

        sdf_aligned = sdf[aligned_cols].copy()
        aligned_dfs.append(sdf_aligned)

        X2 = sdf[feature_cols].to_numpy(dtype=float)
        y1 = sdf[label_col].to_numpy(dtype=int)

        N = len(sdf)
        (tr0, tr1), (va0, va1), (te0, te1) = time_splits(N, R_TRAIN, R_VAL, R_TEST)
        Xtr2, ytr1 = X2[tr0:tr1], y1[tr0:tr1]
        Xva2, yva1 = X2[va0:va1], y1[va0:va1]
        Xte2, yte1 = X2[te0:te1], y1[te0:te1]

        Xtr, ytr = sliding_window(Xtr2, ytr1, SEQ_LEN, STRIDE)
        Xva, yva = sliding_window(Xva2, yva1, SEQ_LEN, STRIDE)
        Xte, yte = sliding_window(Xte2, yte1, SEQ_LEN, STRIDE)

        if Xtr.size == 0 or Xva.size == 0 or Xte.size == 0:
            continue

        Xtr_s, Xva_s, Xte_s, scaler = standardize_train_only(Xtr, Xva, Xte)

        scaler_path = os.path.join(
            OUT_DIR, f"scaler_{str(sid).replace(':','_').replace('/','-')}.pkl"
        )
        dump(scaler, scaler_path)

        Xtr_list.append(Xtr_s); ytr_list.append(ytr)
        Xva_list.append(Xva_s); yva_list.append(yva)
        Xte_list.append(Xte_s); yte_list.append(yte)

        rows_meta.append({
            "stock_id": str(sid),
            "rows_after_clean": int(len(sdf)),
            "windows_train": int(Xtr_s.shape[0]),
            "windows_val":   int(Xva_s.shape[0]),
            "windows_test":  int(Xte_s.shape[0]),
            "num_features":  int(Xtr_s.shape[-1]),
        })

        cls_rows.append({
            "stock_id": str(sid),
            "train_class_0": int((ytr == 0).sum()),
            "train_class_1": int((ytr == 1).sum()),
            "train_total":   int(ytr.size),
            "val_class_0":   int((yva == 0).sum()),
            "val_class_1":   int((yva == 1).sum()),
            "val_total":     int(yva.size),
            "test_class_0":  int((yte == 0).sum()),
            "test_class_1":  int((yte == 1).sum()),
            "test_total":    int(yte.size),
        })

    if len(Xtr_list) == 0:
        raise RuntimeError("所有股票在滑窗后均为空，请检查参数（SEQ_LEN过长？数据不足？或滞后导致前期被清洗？）")

    X_train = np.concatenate(Xtr_list, axis=0)
    X_val   = np.concatenate(Xva_list, axis=0)
    X_test  = np.concatenate(Xte_list, axis=0)
    y_train = np.concatenate(ytr_list, axis=0)
    y_val   = np.concatenate(yva_list, axis=0)
    y_test  = np.concatenate(yte_list, axis=0)

    np.save(os.path.join(OUT_DIR, "X_train.npy"), X_train)
    np.save(os.path.join(OUT_DIR, "y_train.npy"), y_train)
    np.save(os.path.join(OUT_DIR, "X_val.npy"),   X_val)
    np.save(os.path.join(OUT_DIR, "y_val.npy"),   y_val)
    np.save(os.path.join(OUT_DIR, "X_test.npy"),  X_test)
    np.save(os.path.join(OUT_DIR, "y_test.npy"),  y_test)

    cls_df  = pd.DataFrame(cls_rows)
    meta_df = pd.DataFrame(rows_meta)
    cls_df.to_csv(os.path.join(OUT_DIR, "class_distribution_by_stock.csv"),
                  index=False, encoding="utf-8-sig")
    meta_df.to_csv(os.path.join(OUT_DIR, "meta_per_stock.csv"),
                   index=False, encoding="utf-8-sig")

    overall = pd.DataFrame([{
        "input_csv": IN_CSV,
        "out_dir": OUT_DIR,
        "date_col": date_col,
        "stock_col": stock_col,
        "target_source": target_col_cand if target_col_cand is not None else "label_binary",
        "ratios": json.dumps({"train": R_TRAIN, "val": R_VAL, "test": R_TEST}),
        "seq_len": SEQ_LEN,
        "stride": STRIDE,
        "num_features": int(X_train.shape[-1]),
        "num_stocks_used": int(len(meta_df)),
        "X_train_shape": str(list(X_train.shape)),
        "X_val_shape":   str(list(X_val.shape)),
        "X_test_shape":  str(list(X_test.shape)),
        "add_label_lags": ADD_LABEL_LAGS,
        "label_lag_steps": json.dumps(LABEL_LAG_STEPS),
    }])
    overall.to_csv(os.path.join(OUT_DIR, "meta_summary.csv"), index=False, encoding="utf-8-sig")

    if len(aligned_dfs) > 0:
        df_aligned = pd.concat(aligned_dfs, axis=0, ignore_index=True)
        df_aligned.to_csv(
            os.path.join(OUT_DIR, "features_labels_aligned.csv"),
            index=False,
            encoding="utf-8-sig"
        )
        print("已保存对齐表: features_labels_aligned.csv")
    else:
        print("警告：aligned_dfs 为空，未生成 features_labels_aligned.csv（可能所有股票都被过滤掉）")

    print("==== 预处理完成 ====")
    print(f"输出目录: {OUT_DIR}")
    print(f"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}")
    print(f"y_train: {y_train.shape}, y_val: {y_val.shape}, y_test: {y_test.shape}")
    print("每股统计（前5行示例）：")
    print(meta_df.head(5))


if __name__ == "__main__":
    main()
